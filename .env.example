# ============================================
# Harper Configuration
# ============================================
# Harper instance URL for CLI tools
# HARPER_URL=http://localhost:9926
# CLI_TARGET_URL=http://localhost:9926  # Alternative name

# ============================================
# Deployment Configuration (for deploy.sh)
# ============================================
# Remote Harper instance for deployment
# DEPLOY_REMOTE_HOST=ai-ops.irjudson-ai.harperfabric.com
# DEPLOY_REMOTE_PORT=9925
# DEPLOY_REMOTE_URL=https://ai-ops.irjudson-ai.harperfabric.com:9925

# Harper admin credentials for deployment
# DEPLOY_USERNAME=HDB_ADMIN
# DEPLOY_PASSWORD=your-password

# ============================================
# Ollama Configuration
# ============================================
# HTTP endpoint for Ollama server
OLLAMA_HOST=http://localhost:11434
# Default LLM model to use with Ollama
OLLAMA_DEFAULT_MODEL=llama2

# ============================================
# Inference Engine Configuration
# ============================================
# Maximum number of models to keep in LRU cache
MODEL_CACHE_SIZE=10

# ============================================
# Model Fetch System
# ============================================
# Optional shared token for Model Fetch API authentication
# If not set, authentication is disabled (open access)
# MODEL_FETCH_TOKEN=your-secret-token-here

# Enable/disable background worker for model fetching
MODEL_FETCH_WORKER_ENABLED=true

# Maximum concurrent fetch jobs
MODEL_FETCH_MAX_CONCURRENT=3

# Worker poll interval in milliseconds
MODEL_FETCH_POLL_INTERVAL=5000

# Maximum file size for model downloads (bytes)
MODEL_FETCH_MAX_FILE_SIZE=5368709120

# Maximum retry attempts for failed jobs
MODEL_FETCH_MAX_RETRIES=3

# Initial retry delay in milliseconds
MODEL_FETCH_INITIAL_RETRY_DELAY=5000

# ============================================
# Debug Mode
# ============================================
# Enable debug logging throughout the application
DEBUG=false
